# -*- coding: utf-8 -*-
"""03.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PVfMF5Df04IJ_HUiYwonxVYOMZJXTDST
"""

# Commented out IPython magic to ensure Python compatibility.
# %run my_init.py

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

df = pd.read_csv('http://bit.ly/perch_csv_data')
df.head()

perch_full = df.to_numpy()
perch_full[:5]

perch_weight = np.array([5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, 110.0,
       115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, 130.0,
       150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, 197.0,
       218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, 514.0,
       556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, 820.0,
       850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, 1000.0,
       1000.0])

perch_full.shape, perch_weight.shape

train_input, test_input, train_target, test_target = train_test_split(perch_full, perch_weight, random_state=42)

train_input.shape, train_target.shape

test_input.shape, test_target.shape

"""## 특성 공학

기존에 있던 특성으로 새로운 특성을 만듦
"""

poly = PolynomialFeatures(degree = 2, include_bias = False)
train_poly = poly.fit_transform(train_input)
train_poly.shape # 3개 특성이 9개로 증가

poly.get_feature_names_out()

test_poly = poly.transform(test_input)

test_poly.shape

lr = LinearRegression()
lr.fit(train_poly, train_target)

r2_score(train_target, lr.predict(train_poly))

r2_score(test_target, lr.predict(test_poly))

"""degree가 1~5중 overfit 혹은 underfit 문제가 해소되는 다중회귀모델을 만드십시오"""

from typing_extensions import Concatenate
train_scores = np.zeros(5)
test_scores = np.zeros(5)
for i in range(1, 6):
  # poly = PolynomialFeatures(degree = i, incoude_bias = False)
  poly.degree = i
  train_poly = poly.fit_transform(train_input)
  test_poly = poly.transform(test_input)
  lr = LinearRegression()
  lr.fit(train_poly, train_target)
  train_scores[i-1] = r2_score(train_target, lr.predict(train_poly))
  test_scores[i-1] = r2_score(test_target, lr.predict(test_poly))
  print(f"{i} degree, feature # : {train_poly.shape[1]}")
  print(f"train score : {r2_score(train_target, lr.predict(train_poly))}")
  print(f"test score : {r2_score(test_target, lr.predict(test_poly))}")
  print("-----------------------------------------------")
scores = np.stack((train_scores, test_scores),axis=1)
print(scores)